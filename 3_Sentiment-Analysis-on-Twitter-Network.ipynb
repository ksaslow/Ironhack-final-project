{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SENTIMENT ANALYSIS ON TWITTER DATA\n",
    "\n",
    "### IS MY GERMAN OR AMERICAN TWITTER NETWORK \"HAPPIER\" ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 0:\n",
    "### Importing libraries and data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('wordnet')\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('vader_lexicon') \n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "import re\n",
    "import string\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from textblob import TextBlob\n",
    "from textblob_de import TextBlobDE\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# sns.set_palette('Set3')\n",
    "# sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import df with tweets from previous notebook:\n",
    "tweets = pd.read_csv('tweets_to_preprocess_NLP.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets.drop('Unnamed: 0', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets.drop('Geocode', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets.drop(['Location_code', 'Friend', 'First_Name'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TweetText</th>\n",
       "      <th>Handle</th>\n",
       "      <th>ID</th>\n",
       "      <th>CreatedAt</th>\n",
       "      <th>Follower</th>\n",
       "      <th>Location</th>\n",
       "      <th>UserDescription</th>\n",
       "      <th>Country</th>\n",
       "      <th>Gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RT @z_edian: Unser @snv_berlin Expert:innenwor...</td>\n",
       "      <td>christinacrupp</td>\n",
       "      <td>1359905846659059713</td>\n",
       "      <td>2021-02-11 16:43:14</td>\n",
       "      <td>Christina Rupp</td>\n",
       "      <td>Bonn, Deutschland</td>\n",
       "      <td>Project Assistant International Cybersecurity ...</td>\n",
       "      <td>Germany</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RT @rachel_groves: Daily goals: Wake up early....</td>\n",
       "      <td>joscchh</td>\n",
       "      <td>1359905846659059713</td>\n",
       "      <td>2021-02-11 16:43:14</td>\n",
       "      <td>Johanna Sch√§fer</td>\n",
       "      <td>Bonn, Deutschland</td>\n",
       "      <td>CEO @BonnLAB, urban developer &amp; #SocialMedia e...</td>\n",
       "      <td>Germany</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RT @michael_adler_: Fing gut an! Bonn braucht ...</td>\n",
       "      <td>joscchh</td>\n",
       "      <td>1359101568390414337</td>\n",
       "      <td>2021-02-09 11:27:19</td>\n",
       "      <td>Johanna Sch√§fer</td>\n",
       "      <td>Bonn, Deutschland</td>\n",
       "      <td>CEO @BonnLAB, urban developer &amp; #SocialMedia e...</td>\n",
       "      <td>Germany</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RT @EurAsiaBridgeEU: good topic - well done.</td>\n",
       "      <td>joscchh</td>\n",
       "      <td>1359019191358156802</td>\n",
       "      <td>2021-02-09 5:59:59</td>\n",
       "      <td>Johanna Sch√§fer</td>\n",
       "      <td>Bonn, Deutschland</td>\n",
       "      <td>CEO @BonnLAB, urban developer &amp; #SocialMedia e...</td>\n",
       "      <td>Germany</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gestern haben @Lichtemomente, @askans, @michae...</td>\n",
       "      <td>joscchh</td>\n",
       "      <td>1359015354828210176</td>\n",
       "      <td>2021-02-09 5:44:44</td>\n",
       "      <td>Johanna Sch√§fer</td>\n",
       "      <td>Bonn, Deutschland</td>\n",
       "      <td>CEO @BonnLAB, urban developer &amp; #SocialMedia e...</td>\n",
       "      <td>Germany</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           TweetText          Handle  \\\n",
       "0  RT @z_edian: Unser @snv_berlin Expert:innenwor...  christinacrupp   \n",
       "1  RT @rachel_groves: Daily goals: Wake up early....         joscchh   \n",
       "2  RT @michael_adler_: Fing gut an! Bonn braucht ...         joscchh   \n",
       "3       RT @EurAsiaBridgeEU: good topic - well done.         joscchh   \n",
       "4  Gestern haben @Lichtemomente, @askans, @michae...         joscchh   \n",
       "\n",
       "                    ID            CreatedAt         Follower  \\\n",
       "0  1359905846659059713  2021-02-11 16:43:14   Christina Rupp   \n",
       "1  1359905846659059713  2021-02-11 16:43:14  Johanna Sch√§fer   \n",
       "2  1359101568390414337  2021-02-09 11:27:19  Johanna Sch√§fer   \n",
       "3  1359019191358156802   2021-02-09 5:59:59  Johanna Sch√§fer   \n",
       "4  1359015354828210176   2021-02-09 5:44:44  Johanna Sch√§fer   \n",
       "\n",
       "            Location                                    UserDescription  \\\n",
       "0  Bonn, Deutschland  Project Assistant International Cybersecurity ...   \n",
       "1  Bonn, Deutschland  CEO @BonnLAB, urban developer & #SocialMedia e...   \n",
       "2  Bonn, Deutschland  CEO @BonnLAB, urban developer & #SocialMedia e...   \n",
       "3  Bonn, Deutschland  CEO @BonnLAB, urban developer & #SocialMedia e...   \n",
       "4  Bonn, Deutschland  CEO @BonnLAB, urban developer & #SocialMedia e...   \n",
       "\n",
       "   Country  Gender  \n",
       "0  Germany  female  \n",
       "1  Germany  female  \n",
       "2  Germany  female  \n",
       "3  Germany  female  \n",
       "4  Germany  female  "
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1:\n",
    "### Before pre-processing the data for NLP, separate tweet by language:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langdetect import detect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'de'"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detect(tweets['TweetText'][0])\n",
    "# it detects the first tweet as being German"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'en'"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detect(tweets['TweetText'][1])\n",
    "# and it detects the second tweet as being English. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in tweets['TweetText'].iteritems():\n",
    "    try:\n",
    "        lang = detect(row)\n",
    "        \n",
    "    except:\n",
    "        lang = 0\n",
    "        \n",
    "    tweets.loc[index, 'Language'] = lang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tweets['Language'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tweets.drop(['Friend', 'Location_code'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tweets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Text Cleanup:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove RT, Punctuation, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add new column in df to clean up the texts\n",
    "tweets['text'] = tweets['TweetText']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       RT @z_edian: Unser @snv_berlin Expert:innenwor...\n",
       "1       RT @rachel_groves: Daily goals: Wake up early....\n",
       "2       RT @michael_adler_: Fing gut an! Bonn braucht ...\n",
       "3            RT @EurAsiaBridgeEU: good topic - well done.\n",
       "4       Gestern haben @Lichtemomente, @askans, @michae...\n",
       "                              ...                        \n",
       "8420    RT @jana_hensel: Friedrich Merz hat eine Frau ...\n",
       "8421    Ich h√§tte nie gedacht, dass ich das mal sage. ...\n",
       "8422    RT @Mareicares: Dass da echt eine Frau ihren J...\n",
       "8423    RT @Nilzenburger: Sich so einen perfiden Begri...\n",
       "8424    Hat gerade ein Foto gepostet @ Berlin, Germany...\n",
       "Name: text, Length: 8425, dtype: object"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_tweets = list(tweets['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "test= tweets.iloc[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RT @z_edian: Unser @snv_berlin Expert:innenworkshop zur \"staatlichen Beantwortung von b√∂swilligen Cyberaktivit√§ten\" geht langsam zuende.\\n\\nD‚Ä¶'"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_rt = lambda x: re.sub('RT @\\w+: ', \"\", x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab = lambda x: re.sub('[^√§√∂√º√Ñ√ñ√úA-Za-z ]+','', x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Unser @snv_berlin Expert:innenworkshop zur \"staatlichen Beantwortung von b√∂swilligen Cyberaktivit√§ten\" geht langsam zuende.\\n\\nD‚Ä¶'"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test1 = remove_rt(test)\n",
    "test1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "test2 = lab(test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'unser snvberlin expertinnenworkshop zur staatlichen beantwortung von b√∂swilligen cyberaktivit√§ten geht langsam zuended'"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test2.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make this into a function:\n",
    "\n",
    "def clean_up(x):\n",
    "    \"\"\" Clean up the text before NLP. \n",
    "    Remove Punctuation, remove retweet and @.\n",
    "    Keep German characters as vowels.\"\"\"\n",
    "    \n",
    "    remove_rt = lambda x: re.sub('RT @\\w+: ', \"\", x)\n",
    "    lab = lambda x: re.sub('[^√§√∂√º√Ñ√ñ√úA-Za-z ]+','', x)\n",
    "    tw_1 = remove_rt(x)\n",
    "    tw_2 = lab(tw_1)\n",
    "    tw_3 =  tw_2.lower()\n",
    "    \n",
    "    return tw_3\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'unser snvberlin expertinnenworkshop zur staatlichen beantwortung von b√∂swilligen cyberaktivit√§ten geht langsam zuended'"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test the function with 1 tweet before applying to the column\n",
    "clean_up('RT @z_edian: Unser @snv_berlin Expert:innenworkshop zur \"staatlichen Beantwortung von b√∂swilligen Cyberaktivit√§ten\" geht langsam zuende.\\n\\nD‚Ä¶')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets['text'] = tweets['text'].apply(clean_up)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tweets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(x):\n",
    "    \"\"\"Tokenize the tweets.\"\"\"\n",
    "    \n",
    "    from nltk.tokenize import word_tokenize\n",
    "    tokenized_x = word_tokenize(x)\n",
    "    return tokenized_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['unser',\n",
       " 'snvberlin',\n",
       " 'expertinnenworkshop',\n",
       " 'zur',\n",
       " 'staatlichen',\n",
       " 'beantwortung',\n",
       " 'von',\n",
       " 'b√∂swilligen',\n",
       " 'cyberaktivit√§ten',\n",
       " 'geht',\n",
       " 'langsam',\n",
       " 'zuended']"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize(tweets['text'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets['tokenized_tw'] = tweets['text'].apply(tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8425, 12)"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subset in German and English dataframes for the stemming/lemmatizing/vectorizing/analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4791, 12)"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_en = tweets[tweets['Language']=='en']\n",
    "tweets_en.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3070, 12)"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_de = tweets[tweets['Language']=='de']\n",
    "tweets_de.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So there are now a couple hundred tweets dropped from my analysis since the language was either not detected, or not detected as en/de."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stemming and Lemmatization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem_lemmatize_en(l):\n",
    "    \"\"\"This function performs both stemming and lemmatization on our english tweets.\"\"\"\n",
    "    \n",
    "    \n",
    "    from nltk.stem import WordNetLemmatizer\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    l = [lemmatizer.lemmatize(item) for item in l]\n",
    "    from nltk.stem import SnowballStemmer\n",
    "    stemmer = SnowballStemmer(\"english\")\n",
    "    l = [stemmer.stem(item) for item in l]\n",
    "    \n",
    "    return l "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_en['stem_lemm_tw'] = tweets_en['tokenized_tw'].apply(stem_lemmatize_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tweets_en.head()\n",
    "# Does it actually look like the texts have changed enough from stemming and lemmatization?? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem_lemmatize_de(l):\n",
    "    \"\"\"This function performs both stemming and lemmatization on our german tweets.\"\"\"\n",
    "    \n",
    "    \n",
    "    from nltk.stem import WordNetLemmatizer\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    l = [lemmatizer.lemmatize(item) for item in l]\n",
    "    from nltk.stem import SnowballStemmer\n",
    "    stemmer = SnowballStemmer(\"german\")\n",
    "    l = [stemmer.stem(item) for item in l]\n",
    "    \n",
    "    return l "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_de['stem_lemm_tw'] = tweets_de['tokenized_tw'].apply(stem_lemmatize_de)\n",
    "# tweets_de.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stopwords Removal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords_en(l):\n",
    "    \"\"\"Remove english stopwords from a list of tweets.\"\"\"\n",
    "    \n",
    "    from nltk.corpus import stopwords\n",
    "    stopwords_list = stopwords.words(\"english\")\n",
    "    l = [item for item in l if not item in stopwords_list]\n",
    "    \n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_en['remove_stopwords_tw'] = tweets_en['stem_lemm_tw'].apply(remove_stopwords_en)\n",
    "# tweets_en.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords_de(l):\n",
    "    \"\"\"Remove german stopwords from a list of tweets.\"\"\"\n",
    "    \n",
    "    from nltk.corpus import stopwords\n",
    "    stopwords_list = stopwords.words(\"german\")\n",
    "    l = [item for item in l if not item in stopwords_list]\n",
    "    \n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_de['remove_stopwords_tw'] = tweets_de['stem_lemm_tw'].apply(remove_stopwords_de)\n",
    "# tweets_de.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove intermediary processing steps from dfs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TweetText</th>\n",
       "      <th>Handle</th>\n",
       "      <th>Location</th>\n",
       "      <th>Country</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Language</th>\n",
       "      <th>text_processed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RT @rachel_groves: Daily goals: Wake up early....</td>\n",
       "      <td>joscchh</td>\n",
       "      <td>Bonn, Deutschland</td>\n",
       "      <td>Germany</td>\n",
       "      <td>female</td>\n",
       "      <td>en</td>\n",
       "      <td>[daili, goal, wake, earli, drink, coffe, work,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RT @EurAsiaBridgeEU: good topic - well done.</td>\n",
       "      <td>joscchh</td>\n",
       "      <td>Bonn, Deutschland</td>\n",
       "      <td>Germany</td>\n",
       "      <td>female</td>\n",
       "      <td>en</td>\n",
       "      <td>[good, topic, well, done]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>@jpbrice Life is always precious - every singl...</td>\n",
       "      <td>joscchh</td>\n",
       "      <td>Bonn, Deutschland</td>\n",
       "      <td>Germany</td>\n",
       "      <td>female</td>\n",
       "      <td>en</td>\n",
       "      <td>[jpbrice, life, alway, precious, everi, singl,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>@PeterShepherd8 @MYorke27 @ZEReadyOregon Great...</td>\n",
       "      <td>joscchh</td>\n",
       "      <td>Bonn, Deutschland</td>\n",
       "      <td>Germany</td>\n",
       "      <td>female</td>\n",
       "      <td>en</td>\n",
       "      <td>[petershepherd, myork, zereadyoregon, great, l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>RT @jpbrice: ‚ÄúYou never know how strong you ar...</td>\n",
       "      <td>joscchh</td>\n",
       "      <td>Bonn, Deutschland</td>\n",
       "      <td>Germany</td>\n",
       "      <td>female</td>\n",
       "      <td>en</td>\n",
       "      <td>[never, know, strong, strong, onli, choic, quo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            TweetText   Handle  \\\n",
       "1   RT @rachel_groves: Daily goals: Wake up early....  joscchh   \n",
       "3        RT @EurAsiaBridgeEU: good topic - well done.  joscchh   \n",
       "8   @jpbrice Life is always precious - every singl...  joscchh   \n",
       "11  @PeterShepherd8 @MYorke27 @ZEReadyOregon Great...  joscchh   \n",
       "12  RT @jpbrice: ‚ÄúYou never know how strong you ar...  joscchh   \n",
       "\n",
       "             Location  Country  Gender Language  \\\n",
       "1   Bonn, Deutschland  Germany  female       en   \n",
       "3   Bonn, Deutschland  Germany  female       en   \n",
       "8   Bonn, Deutschland  Germany  female       en   \n",
       "11  Bonn, Deutschland  Germany  female       en   \n",
       "12  Bonn, Deutschland  Germany  female       en   \n",
       "\n",
       "                                       text_processed  \n",
       "1   [daili, goal, wake, earli, drink, coffe, work,...  \n",
       "3                           [good, topic, well, done]  \n",
       "8   [jpbrice, life, alway, precious, everi, singl,...  \n",
       "11  [petershepherd, myork, zereadyoregon, great, l...  \n",
       "12  [never, know, strong, strong, onli, choic, quo...  "
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_en.drop(['tokenized_tw', 'stem_lemm_tw', 'text', 'UserDescription', 'CreatedAt', 'ID', 'Follower'], axis=1, inplace=True)\n",
    "tweets_en.rename(columns={'remove_stopwords_tw': 'text_processed'}, inplace=True)\n",
    "tweets_en.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TweetText</th>\n",
       "      <th>Handle</th>\n",
       "      <th>Location</th>\n",
       "      <th>Country</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Language</th>\n",
       "      <th>text_processed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RT @z_edian: Unser @snv_berlin Expert:innenwor...</td>\n",
       "      <td>christinacrupp</td>\n",
       "      <td>Bonn, Deutschland</td>\n",
       "      <td>Germany</td>\n",
       "      <td>female</td>\n",
       "      <td>de</td>\n",
       "      <td>[snvberlin, expertinnenworkshop, staatlich, be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RT @michael_adler_: Fing gut an! Bonn braucht ...</td>\n",
       "      <td>joscchh</td>\n",
       "      <td>Bonn, Deutschland</td>\n",
       "      <td>Germany</td>\n",
       "      <td>female</td>\n",
       "      <td>de</td>\n",
       "      <td>[fing, gut, bonn, braucht, mindshift, autostad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gestern haben @Lichtemomente, @askans, @michae...</td>\n",
       "      <td>joscchh</td>\n",
       "      <td>Bonn, Deutschland</td>\n",
       "      <td>Germany</td>\n",
       "      <td>female</td>\n",
       "      <td>de</td>\n",
       "      <td>[gest, lichtemoment, askan, michaeladl, barbar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>@VolkerGoebbels Macht Sinn üòè</td>\n",
       "      <td>joscchh</td>\n",
       "      <td>Bonn, Deutschland</td>\n",
       "      <td>Germany</td>\n",
       "      <td>female</td>\n",
       "      <td>de</td>\n",
       "      <td>[volkergoebbel, macht, sinn]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>@jbrunotte Was waren denn deine Beweggr√ºnde da...</td>\n",
       "      <td>joscchh</td>\n",
       "      <td>Bonn, Deutschland</td>\n",
       "      <td>Germany</td>\n",
       "      <td>female</td>\n",
       "      <td>de</td>\n",
       "      <td>[jbrunott, wa, beweggrund, dafur, spannend, wiss]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           TweetText          Handle  \\\n",
       "0  RT @z_edian: Unser @snv_berlin Expert:innenwor...  christinacrupp   \n",
       "2  RT @michael_adler_: Fing gut an! Bonn braucht ...         joscchh   \n",
       "4  Gestern haben @Lichtemomente, @askans, @michae...         joscchh   \n",
       "5                       @VolkerGoebbels Macht Sinn üòè         joscchh   \n",
       "6  @jbrunotte Was waren denn deine Beweggr√ºnde da...         joscchh   \n",
       "\n",
       "            Location  Country  Gender Language  \\\n",
       "0  Bonn, Deutschland  Germany  female       de   \n",
       "2  Bonn, Deutschland  Germany  female       de   \n",
       "4  Bonn, Deutschland  Germany  female       de   \n",
       "5  Bonn, Deutschland  Germany  female       de   \n",
       "6  Bonn, Deutschland  Germany  female       de   \n",
       "\n",
       "                                      text_processed  \n",
       "0  [snvberlin, expertinnenworkshop, staatlich, be...  \n",
       "2  [fing, gut, bonn, braucht, mindshift, autostad...  \n",
       "4  [gest, lichtemoment, askan, michaeladl, barbar...  \n",
       "5                       [volkergoebbel, macht, sinn]  \n",
       "6  [jbrunott, wa, beweggrund, dafur, spannend, wiss]  "
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_de.drop(['tokenized_tw', 'stem_lemm_tw', 'text', 'UserDescription', 'CreatedAt', 'ID', 'Follower'], axis=1, inplace=True)\n",
    "tweets_de.rename(columns={'remove_stopwords_tw': 'text_processed'}, inplace=True)\n",
    "tweets_de.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: \n",
    "### Sentiment Analysis with TextBlob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating Negative, Positive, and/or Neutral Values.\n",
    "* REMEMBER - the tweets in tweets_en means that they are English-language tweets, NOT that they come from my American network. \n",
    "* REMEMBER - the tweets in tweets_de means that they are German-language tweets, NOT that they come from my German network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using Python package TextBlob to calculate polarity values of individual tweets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.19404761904761905,\n",
       " TextBlob(\"RT @rachel_groves: Daily goals: Wake up early. Drink coffee. Work hard. Be ambitious. Do what you love. Love what you do. Have fun. #inspir‚Ä¶\"))"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_objects_en = [TextBlob(tweet) for tweet in tweets_en['TweetText']]\n",
    "\n",
    "sentiment_objects_en[0].polarity, sentiment_objects_en[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add polarity column to the dataframes:\n",
    "\n",
    "tweets_en['Polarity'] = [i.polarity for i in sentiment_objects_en]\n",
    "# tweets_en.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.35,\n",
       " TextBlobDE(\"RT @z_edian: Unser @snv_berlin Expert:innenworkshop zur \"staatlichen Beantwortung von b√∂swilligen Cyberaktivit√§ten\" geht langsam zuende.\n",
       " \n",
       " D‚Ä¶\"))"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_objects_de = [TextBlobDE(tweet) for tweet in tweets_de['TweetText']]\n",
    "\n",
    "sentiment_objects_de[0].polarity, sentiment_objects_de[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_de['Polarity'] = [i.polarity for i in sentiment_objects_de]\n",
    "# tweets_de.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add polarity column to df of all tweets and plot polarity by location rather than language."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using Python package TextBlob to calculate sentiment (pos/neg) values of individual tweets:\n",
    "\n",
    "TextBlob sentiment returns polarity score and subjectivity score. \n",
    "If polarity > 0, it is considered positive, if  polarity < 0, it is considered negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Sentiment(polarity=0.19404761904761905, subjectivity=0.42738095238095236),\n",
       " TextBlob(\"RT @rachel_groves: Daily goals: Wake up early. Drink coffee. Work hard. Be ambitious. Do what you love. Love what you do. Have fun. #inspir‚Ä¶\"))"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_objects_en = [TextBlob(tweet) for tweet in tweets_en['TweetText']]\n",
    "\n",
    "sentiment_objects_en[0].sentiment, sentiment_objects_en[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add column w. subjectivity score to each df\n",
    "tweets_en['Subjectivity'] = [i.sentiment[1] for i in sentiment_objects_en]\n",
    "# tweets_en.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_de['Subjectivity'] = [i.sentiment[1] for i in sentiment_objects_de]\n",
    "# tweets_de.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add column with sentiment (pos/neg/neu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_category_en = ['positive' if score >0\n",
    "                         else 'negative' if score<0\n",
    "                             else 'neutral'\n",
    "                                  for score in tweets_en['Polarity']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'negative']"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_category_en[:20] \n",
    "# Make sure it worked, then add to df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_en['Sentiment'] = sentiment_category_en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tweets_en.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_category_de = ['positive' if score >0\n",
    "                         else 'negative' if score<0\n",
    "                             else 'neutral'\n",
    "                                  for score in tweets_de['Polarity']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['negative',\n",
       " 'positive',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'neutral',\n",
       " 'positive',\n",
       " 'neutral',\n",
       " 'positive',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'positive',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'neutral']"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_category_de[:20] \n",
    "# Make sure it worked, then add to df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_de['Sentiment'] = sentiment_category_de"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TweetText</th>\n",
       "      <th>Handle</th>\n",
       "      <th>Location</th>\n",
       "      <th>Country</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Language</th>\n",
       "      <th>text_processed</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Subjectivity</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RT @z_edian: Unser @snv_berlin Expert:innenwor...</td>\n",
       "      <td>christinacrupp</td>\n",
       "      <td>Bonn, Deutschland</td>\n",
       "      <td>Germany</td>\n",
       "      <td>female</td>\n",
       "      <td>de</td>\n",
       "      <td>[snvberlin, expertinnenworkshop, staatlich, be...</td>\n",
       "      <td>-0.350000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RT @michael_adler_: Fing gut an! Bonn braucht ...</td>\n",
       "      <td>joscchh</td>\n",
       "      <td>Bonn, Deutschland</td>\n",
       "      <td>Germany</td>\n",
       "      <td>female</td>\n",
       "      <td>de</td>\n",
       "      <td>[fing, gut, bonn, braucht, mindshift, autostad...</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.25</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gestern haben @Lichtemomente, @askans, @michae...</td>\n",
       "      <td>joscchh</td>\n",
       "      <td>Bonn, Deutschland</td>\n",
       "      <td>Germany</td>\n",
       "      <td>female</td>\n",
       "      <td>de</td>\n",
       "      <td>[gest, lichtemoment, askan, michaeladl, barbar...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>@VolkerGoebbels Macht Sinn üòè</td>\n",
       "      <td>joscchh</td>\n",
       "      <td>Bonn, Deutschland</td>\n",
       "      <td>Germany</td>\n",
       "      <td>female</td>\n",
       "      <td>de</td>\n",
       "      <td>[volkergoebbel, macht, sinn]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>@jbrunotte Was waren denn deine Beweggr√ºnde da...</td>\n",
       "      <td>joscchh</td>\n",
       "      <td>Bonn, Deutschland</td>\n",
       "      <td>Germany</td>\n",
       "      <td>female</td>\n",
       "      <td>de</td>\n",
       "      <td>[jbrunott, wa, beweggrund, dafur, spannend, wiss]</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>0.00</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           TweetText          Handle  \\\n",
       "0  RT @z_edian: Unser @snv_berlin Expert:innenwor...  christinacrupp   \n",
       "2  RT @michael_adler_: Fing gut an! Bonn braucht ...         joscchh   \n",
       "4  Gestern haben @Lichtemomente, @askans, @michae...         joscchh   \n",
       "5                       @VolkerGoebbels Macht Sinn üòè         joscchh   \n",
       "6  @jbrunotte Was waren denn deine Beweggr√ºnde da...         joscchh   \n",
       "\n",
       "            Location  Country  Gender Language  \\\n",
       "0  Bonn, Deutschland  Germany  female       de   \n",
       "2  Bonn, Deutschland  Germany  female       de   \n",
       "4  Bonn, Deutschland  Germany  female       de   \n",
       "5  Bonn, Deutschland  Germany  female       de   \n",
       "6  Bonn, Deutschland  Germany  female       de   \n",
       "\n",
       "                                      text_processed  Polarity  Subjectivity  \\\n",
       "0  [snvberlin, expertinnenworkshop, staatlich, be... -0.350000          0.00   \n",
       "2  [fing, gut, bonn, braucht, mindshift, autostad...  0.250000          0.25   \n",
       "4  [gest, lichtemoment, askan, michaeladl, barbar...  0.000000          0.00   \n",
       "5                       [volkergoebbel, macht, sinn]  0.000000          0.00   \n",
       "6  [jbrunott, wa, beweggrund, dafur, spannend, wiss]  0.233333          0.00   \n",
       "\n",
       "  Sentiment  \n",
       "0  negative  \n",
       "2  positive  \n",
       "4   neutral  \n",
       "5   neutral  \n",
       "6  positive  "
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_de.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3:\n",
    "### Putting the en/de tweets back into one dataframe for continued analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4791\n",
      "3070\n"
     ]
    }
   ],
   "source": [
    "print(len(tweets_en))\n",
    "print(len(tweets_de))\n",
    "\n",
    "# Save both en/de dataframes to csv for wordcloud in separate analysis:\n",
    "tweets_en.to_csv('tweets_en.csv')\n",
    "tweets_de.to_csv('tweets_de.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tweets_analysis = pd.concat([tweets_en, tweets_de], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save df to csv:\n",
    "\n",
    "tweets_analysis.to_csv('tweets_analysis.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Germany    5662\n",
       "USA        2199\n",
       "Name: Country, dtype: int64"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_analysis['Country'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(tweets_analysis['text_processed'][0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [daili, goal, wake, earli, drink, coffe, work,...\n",
       "1                               [good, topic, well, done]\n",
       "2       [jpbrice, life, alway, precious, everi, singl,...\n",
       "3       [petershepherd, myork, zereadyoregon, great, l...\n",
       "4       [never, know, strong, strong, onli, choic, quo...\n",
       "                              ...                        \n",
       "7856    [friedrich, merz, frau, geheiratet, mehr, femi...\n",
       "7857    [hatt, nie, gedacht, mal, sag, druck, arminlas...\n",
       "7858    [echt, frau, job, abgibt, au, grund, einfach, ...\n",
       "7859    [perfid, begriff, neidsteu, uberhaupt, ausdenk...\n",
       "7860    [gerad, foto, gepostet, berlin, germany, https...\n",
       "Name: text_processed, Length: 7861, dtype: object"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_analysis['text_processed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Since absolute numbers aren't telling, maybe look at ratio of positive:total tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweets from German Network:  5662\n",
      "Tweets from American Network:  2199\n"
     ]
    }
   ],
   "source": [
    "# Get length of German-region tweets for ratio:\n",
    "\n",
    "ger = tweets_analysis[tweets_analysis['Country']=='Germany']\n",
    "print(\"Tweets from German Network: \", len(ger))\n",
    "\n",
    "usa = tweets_analysis[tweets_analysis['Country']=='USA']\n",
    "print(\"Tweets from American Network: \", len(usa))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4492951341518872"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratio_us_pos = len(tweets_analysis[(tweets_analysis['Country']=='USA') & (tweets_analysis['Sentiment']=='positive')])/len(usa)\n",
    "ratio_us_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.36276933945602263"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratio_de_pos = len(tweets_analysis[(tweets_analysis['Country']=='Germany') & (tweets_analysis['Sentiment']=='positive')])/len(ger)\n",
    "ratio_de_pos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4:\n",
    "### Continue on here if time?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RETURN TO HERE:\n",
    "\n",
    "Although the graphs of all tweets make it seem that German Network is more positive, the ratio of positive tweets: all tweets in the US is 10% higher!\n",
    "\n",
    "Get the predict_proba probability from TextBlob next!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Subjectivity</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Country</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Germany</th>\n",
       "      <td>0.121243</td>\n",
       "      <td>0.183735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>USA</th>\n",
       "      <td>0.130116</td>\n",
       "      <td>0.328719</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Polarity  Subjectivity\n",
       "Country                        \n",
       "Germany  0.121243      0.183735\n",
       "USA      0.130116      0.328719"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try Groupby country:\n",
    "tweets_analysis.groupby(['Country']).mean()\n",
    "\n",
    "# Overall, while average tweets tend to be neutral, American tweets tend to be more SUBJECTIVE. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Subjectivity</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Country</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">Germany</th>\n",
       "      <th>negative</th>\n",
       "      <td>-0.325036</td>\n",
       "      <td>0.282079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neutral</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.060850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>positive</th>\n",
       "      <td>0.423306</td>\n",
       "      <td>0.338951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">USA</th>\n",
       "      <th>negative</th>\n",
       "      <td>-0.250050</td>\n",
       "      <td>0.472570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neutral</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.075839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>positive</th>\n",
       "      <td>0.359453</td>\n",
       "      <td>0.527850</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Polarity  Subjectivity\n",
       "Country Sentiment                        \n",
       "Germany negative  -0.325036      0.282079\n",
       "        neutral    0.000000      0.060850\n",
       "        positive   0.423306      0.338951\n",
       "USA     negative  -0.250050      0.472570\n",
       "        neutral    0.000000      0.075839\n",
       "        positive   0.359453      0.527850"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_country = tweets_analysis.groupby(['Country', 'Sentiment']).mean()\n",
    "grouped_country\n",
    "\n",
    "# Overall, American tweets tend to be more SUBJECTIVE, in both positive and negative tweets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Subjectivity</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gender</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">female</th>\n",
       "      <th>negative</th>\n",
       "      <td>-0.286795</td>\n",
       "      <td>0.368513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neutral</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.055351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>positive</th>\n",
       "      <td>0.389999</td>\n",
       "      <td>0.441795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">male</th>\n",
       "      <th>negative</th>\n",
       "      <td>-0.324953</td>\n",
       "      <td>0.320576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neutral</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.073991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>positive</th>\n",
       "      <td>0.414592</td>\n",
       "      <td>0.364161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">unknown</th>\n",
       "      <th>negative</th>\n",
       "      <td>-0.244688</td>\n",
       "      <td>0.344207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neutral</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.059023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>positive</th>\n",
       "      <td>0.409246</td>\n",
       "      <td>0.363201</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Polarity  Subjectivity\n",
       "Gender  Sentiment                        \n",
       "female  negative  -0.286795      0.368513\n",
       "        neutral    0.000000      0.055351\n",
       "        positive   0.389999      0.441795\n",
       "male    negative  -0.324953      0.320576\n",
       "        neutral    0.000000      0.073991\n",
       "        positive   0.414592      0.364161\n",
       "unknown negative  -0.244688      0.344207\n",
       "        neutral    0.000000      0.059023\n",
       "        positive   0.409246      0.363201"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_gender = tweets_analysis.groupby(['Gender', 'Sentiment']).mean()\n",
    "grouped_gender"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
